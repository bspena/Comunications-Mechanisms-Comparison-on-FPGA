Here’s a revised and corrected version:

---

# Intel oneAPI Base Toolkit

The `Intel oneAPI Base Toolkit` (known as the `Base Kit`) is an implementation of the oneAPI specification that provides tools and libraries for developing high-performance, data-centric applications across architectures<sup>[[1]](references.md#ref_base_kit)</sup>.

<p align="center">
  <img src="img/img_base_kit.png" width="600">
</p>

## oneAPI <a name="ch_oneapi"></a>

`oneAPI` is a cross-industry, multi-architecture, open standard `programming model`<sup>[[2]](references.md#ref_oneapi)</sup>, ensuring portability and performance across `heterogeneous architectures` (CPUs, GPUs, FPGAs, etc.).

A oneAPI platform<sup>[[3]](references.md#ref_oneapi_arch)</sup> includes:
* `Host`: Typically a multi-core CPU that runs the `host application`.
* `Devices`: One or more accelerators, each with a `command queue`. A device runs a `function object` (or `kernel`), which contains a function definition and associated variables. To execute a kernel on the device, the host application submits a command group containing the kernel to the device’s command queue.

oneAPI is an implementation of the `Khronos SYCL 2020 Specification`<sup>[[4]](references.md#ref_oneapi_sycl)</sup>, a royalty-free programming model based on `ISO C++ 17` and an evolution of `OpenCL`<sup>[[5]](references.md#ref_sycl)</sup>. SYCL enables programming for both CPUs and accelerators, allowing `host code` and `device code` to coexist within the same source file<sup>[[4]](references.md#ref_oneapi_sycl)</sup>.

## Intel oneAPI ASP <a name="ch_oneapi_asp"></a>

The `oneAPI Accelerator Support Package (ASP)`<sup>[[6]](references.md#ref_oneapi_asp_ref)</sup> consists of hardware components that enable communication between the `hardware circuit` (generated by the oneAPI compiler from a SYCL kernel) and the oneAPI runtime and FPGA board peripherals. ASP is equivalent to a `Board Support Package (BSP)`<sup>[[7]](references.md#ref_bsp)</sup>, providing the necessary software and FPGA design layers to target the FPGA through the Intel oneAPI DPC++/C++ Compiler.

ASP includes:
* `Hardware Components`: Enable communication between the hardware circuit and the host processor, divided into:
  * `RTL Components`: Interface logic (e.g., host-to-kernel interface) to handle kernel control signals and manage Direct Memory Access (DMA).
  * `XML Files`: Define hardware interfaces and the compilation environment.
  * `Scripts`: Control the compilation flow.
* `Software Components`: Allow the runtime to identify and communicate with the kernel, divided into:
  * `Memory Mapped Device (MMD) Layer`: Facilitates communication between the host, the oneAPI runtime, the oneAPI kernel, and other oneAPI ASP hardware registers.
  * `oneAPI ASP Utilities`: Used to set up and diagnose the board.

Both ASP hardware components and kernels are located in the `Accelerator Functional Unit (AFU) region`. The AFU is a hardware accelerator implemented in FPGA logic that offloads computational operations from the CPU, enhancing performance. The AFU is part of the `Open FPGA Stack (OFS)`, a modular collection of hardware platform components, open-source software, and broad ecosystem support. OFS provides a standardized, scalable model for AFU and software developers to optimize and reuse their designs.

<p align="center">
  <img src="img/img_HLD_IntelOFS_Model.png" width="550">
</p>

## Pipes <a name="ch_pipes"></a>

A `pipe`<sup>[[8]](references.md#ref_pipes_sample)</sup> is a `unidirectional FIFO data structure` enabling communication between two `endpoints`. An endpoint can be a kernel or an external I/O on the FPGA. There are three types of pipes:
* Kernel-to-Kernel
* Kernel-to-I/O
* I/O-to-Kernel

Data flows in a single direction through a pipe, so `bidirectional communication` requires two pipes. Kernels that exchange data via pipes can execute concurrently.

Communication takes place through `read and write operations`, which can be:
* `Blocking`: Operations may not return immediately but always succeed.
* `Non-blocking`: Operations take an additional boolean parameter that is set to `true` if the operation completes successfully.

A `configurable capacity parameter` defines `n` consecutive writes (without reads). The pipe is considered `full` when this limit is reached. If a write operation is attempted on a full pipe, two outcomes are possible:
* With a blocking operation, the write waits until a read operation frees up space in the pipe.
* With a non-blocking operation, it returns immediately (boolean parameter is set to `false`), and the write has no effect.

The same applies to a read operation attempted on an empty pipe.

## Unified Shared Memory Allocation <a name="ch_usm"></a>

`Unified Shared Memory (USM)`<sup>[[9]](references.md#ref_explicit_sample)</sup> provides a C/C++ pointer-based memory management interface in SYCL, as an alternative to `buffer and accessor SYCL constructs` (also known as `implicit data movement`, where the parallel runtime manages data transfer and synchronization between kernels).

USM offers three types of allocations:
* `Device allocation`: Allocates device memory via `malloc_device`, accessible only on the device.
* `Host allocation`: Allocates host memory via `malloc_host`. The pointer lives in host DDR, but the BSP enables direct access for reading this memory.
* `Shared allocation`: Allocates shared memory via `malloc_shared`, accessible on both host and FPGA, with memory location potentially shifting between host and device at runtime based on access patterns.

With USM, the programmer explicitly:
* Copies data to or from the FPGA DDR using the `SYCL memcpy` function.
* Manages `synchronization between kernels` accessing the same device pointers, using `wait` for SYCL events or the `depends_on` signal between events.

## Intel oneAPI FPGA Development Flows <a name="ch_fpga_flow"></a>

The Base Kit provides two different development flows<sup>[[10]](references.md#ref_fpga_dev)</sup><sup>[[11]](references.md#ref_fpga_dev_flow)</sup>:
* `FPGA Acceleration Flow (Full-Stack Flow)`: Generates a `multiarchitecture binary` (or `fat binary`), containing both host and device code (known as the `SYCL kernel`). Some aspects of the device code depend on the BSP. This full-stack flow is achieved by targeting an FPGA acceleration board in the Intel oneAPI DPC++/C++ Compiler.
* `SYCL High-Level Synthesis Flow (HLS Flow or IP Authoring Flow)`: Translates device code into an `RTL IP core`, using the host code as a testbench for emulation and simulation. The RTL IP core is integrated into the design via Intel Quartus Prime Platform Designer. In this flow, the FPGA capabilities do not depend on the BSP, but the programmer must manage more IP design aspects than with a fat binary. The IP Authoring Flow is undertaken by setting a supported Intel FPGA device family as the compilation target in the Intel oneAPI DPC++/C++ Compiler.

<p align="center">
  <img src="img/img_oneapi_fpga_flow.png" width="300">
</p>