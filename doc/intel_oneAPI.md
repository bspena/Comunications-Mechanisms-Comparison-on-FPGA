# Intel oneAPI Base Toolkit
`Intel oneAPI Base Toolkit` (known as `Base Kit`) is an implementation of the oneAPI specification and provides tools and libraries for developing high-performance, data-centric applications across architectures<sup>[[2]](references.md#ref_base_kit)</sup>.

<p align="center">
  <img src="img/img_base_kit.png" width="600">
  <!-- 
  <em>image_caption</em> -->
</p>



## oneAPI <a name="ch_oneapi"></a>
`oneAPI` is a multi-architecture cross-indutry open standard `programming model`<sup>[[]](references.md#ref_oneapi)</sup> , which guarantees portability and performance across `heterogeneous architectures` (CPUs, GPUs, FPGAs, etc...).

A oneAPI platform<sup>[[]](references.md#ref_oneapi_arch)</sup> includes:
* `Host`: Tipically a multi-core CPU. It runs the `host Application`.
* `Devices`: One or more accelerators, each of them has a `command queue`. A device runs a `function Object` (or `kernel`), which contains a function definition and its related variables. In order to run a kernel on the device, the host application submit a command group, with the kernel, to the device's command queue.

oneAPI is an implementation of `Khronos SYCL 2020 Specification`<sup>[[]](references.md#ref_oneapi_sycl)</sup>, which is a royalty-free proramming launguage based on `ISO C++ 17` and an evolution of `OpenCL`<sup>[[]](references.md#ref_sycl)</sup>. SYCL allows you to program both CPUs and accelerator devices, by mixing both `host code` and `device code` in the same source file<sup>[[]](references.md#ref_oneapi_sycl)</sup>.


## Intel oneAPI ASP <a name="ch_oneapi_asp"></a>
`oneAPI Accelerator Support Package (ASP)`<sup>[[]](references.md#ref_oneapi_asp_ref)</sup>  consists of hardware components that ensure communication between `hardware circuit` (generated by the oneAPI compiler from a SYCL kernel) with the oneAPI runtime and FPGA board peripherals. It is equivalent to a `Board Support Package (BSP)`; the BSP is a set of software layers and an FPGA hardware  design used to target the FPGA through the Intel oneAPI DPC++/C++ Compiler.

ASP is comprised of:
* `Hardware Components`: Enable the hardware circuit to communicate with the host processor. The hardware components are divided into:
  * `RTL Components`: Represent interface logic (host to kernel interface, etc..) to handle kernel control signals and perform Direct Memory Access (DMA).
  * `XML Files`: To describe hardware interfaces and compilation environment.
  * `Scripts`: To control compile flow.
* `Software Components`: Enable the runtime to identify and communicate with the kernel. The software components are divided into:
  * `Memory Mapped Device (MMD) Layer`: Used by the host and oneAPI runtime to communicate with the oneAPI kernel and other oneAPI ASP hardware registers.
  * `oneAPI ASP Utilities`: Used to setup and diagnose the board.

Both ASP hardware components and kernels are placend in the `Accelerator Functional Unit (AFU) region`. The AFU is an hardware accelerator implemented in FPGA logic which offloads a computational operation for an application from the CPU to improve performance.

<p align="center">
  <img src="img/img_HLD_IntelOFS_Model.png" width="550">
</p>



## Pipes <a name="ch_pipes"></a>
A `pipe` is an `unidirectional FIFO data structure` and allows comunication between two `endpoints`, an endpoint can be a kernel or an external I/O on the FPGA<sup>[[]](references.md#ref_pipes_sample)</sup>. There are three types of pipes:
* Kernel-Kernel
* Kernel-I/O
* I/O-Kernel

Into a pipe the data flows in a single direction, so the `bidirectional comunication` is obtained through two pipes. Through the pipe, kernels that exchange data can run concurrently. 

The communication takes place through `read and write operations`, they can be:
* `Blocking`: Operations may not return immediately but are always successful.
* `Non-blocking`: Operations takes an extra boolean parameter that is set to true if the operation happened successfull.

The `n` consecutive writes (without performing any reads) is defined by a `configurable capacity parameter`, the pipe is `full` when the number of consecutive writes executed is equal to n. If a write is performed with a full pipe, two cases can occur:
* With a blocking operation, it does not return until a read is performed by the other endpoint. Once the read is performed, the write takes place.
* With a non-blocking operation, it returns immediately (boolean parameter is set to false), the write does not have an effect.

The same goes for a read performed with an empty pipe.


## Unified Shared Memory Allocation <a name="ch_usm"></a>
The `Unified Shared Memory (USM)` provides a C/C++ pointer-based memory management interfaces in SYCL, which is an alternative to the to the `buffer and accessor SYCL constructs` (also known as `implic data movement`, where the parallel runtime manages data movement and synchronization between kernels). 

USM provides three types of allocations<sup>[[]](references.md#ref_explicit_sample)</sup>:
* `Device allocation`: Allocates device memory through `malloc_device` and is only accessible from the device.
* `Host allocation`: Allocates host memory through `malloc_host`. The pointer given to the FPGA actually lives in the host DDR, but the BSP implements the necessary functionalities to be able to read directly in this memory.
* `Shared allocation`: Allocates shared memory through `malloc_shared`. The memory can live on the host or on the FPGA and may be moved at runtime between the host and device depending on the memory access pattern.

With USM allocation, the programmer explicitly:
* Copies data to or from the FPGA DDR using `SYCL memcpy function`.
* Manages the `synchronization between kernels` accessing the same device pointers using `wait function of a SYCL event` or the `depends_on signal` between events.


## Intel oneAPI FPGA Development Flows <a name="ch_fpga_flow"></a>
The Base Kit provides tow different development flows<sup>[[]](references.md#ref_fpga_dev)</sup><sup>[[]](references.md#ref_fpga_dev_flow)</sup>:
* `FPGA Acceleration Flow (Full-Stack flow)`: Generates the `multiarchitecture binary` (known as `fat binary`). Tha fat binary contains both host and device code (also known as `SYCL kernel`), some aspects of the device code depends on the [Board Support Package (BSP)](#glos_bsp). The full-stack flow is undertaken by setting an FPGA acceleration board as compilation target in Intel oneAPI DPC++/C++ Compiler.
* `SYCL High-Level Synthesis Flow (HLS Flow or IP Authoring Flow)`: Translates the device code into `RTL IP core` and uses the host code as the testbench for the emulation and simulation flows. The RTL IP core has to be intagrated into the design through Intel Quartus Prime Platform Designer. The FPGA capabilities do not depend on the BSP, but the programmer has to manage more section of the IP design than when generating a fat binary. The IP Authoring Flow is undertaken by setting a supported Intel FPGA device family as e compilation target in Intel oneAPI DPC++/C++ Compiler.

<p align="center">
  <img src="img/img_oneapi_fpga_flow.png" width="300">
</p>